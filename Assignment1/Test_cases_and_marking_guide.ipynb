{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP9418 Assignment 1 - Marking Criteria\n",
    "\n",
    "Jeremy has prepared a set of test cases to help us to assess and mark the students' notebooks. Each notebook has a test cell marked with the tag:\n",
    "\n",
    "```\n",
    "############\n",
    "## TEST CODE\n",
    "```\n",
    "\n",
    "These cells may already contain a few test cases. These are **not** true test cases, in a sense, they are there to help the students to understand how their code would be tested. You will replace these test cases by the ones contained in this notebook.\n",
    "\n",
    "For each section, you need to copy the test cases in this notebook and paste to the corresponding test cell in the assignment (student) notebook. These test cases were designed to help you to catch some common issues. However, you still need to read the code to check if it is well-organised and note possible similarities with other assignments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [20 marks] Task 1 - The d-separation algorithm\n",
    "\n",
    "Task 1 has a single test cell. Copy the test cell bellow and paste it to the assignment notebook. This cell has 10 test cases, and each correct one is worth 2 marks.\n",
    "\n",
    "If needed, you can discount up to 5 marks in cases such as:\n",
    "1. It wasn't easy to run the test code since it required a code adaptation of some sort, such as renaming variables, the code destroys the original graph, etc.\n",
    "2. The code looks excessively unorganised or long.\n",
    "3. The code takes excessively long to run. This is a particularly bad thing, since they are required to implement an efficient version of d-separation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# Test code to copy  #\n",
    "######################\n",
    "\n",
    "def test(statement):\n",
    "    if statement:\n",
    "        print(\"Passed test case\")\n",
    "    else:\n",
    "        print(\"Failed test case !!!\")\n",
    "\n",
    "\n",
    "test(not d_separation(G, set(['Age']), set(), set(['Spiculation'])))\n",
    "test(not d_separation(G, set(['Age']), set(['Margin']), set(['Location'])))\n",
    "test(d_separation(G, set(['Age','MC']), set(['FibrTissueDev']), set(['Spiculation'])))\n",
    "test(not d_separation(G, set(['Age','MC']), set([]), set(['Spiculation'])))\n",
    "test(d_separation(G, set(['Age','MC']), set(['Mass','AD']), set(['Spiculation','Margin'])))\n",
    "new_graph = Graph({1:[2],\n",
    "             2:[3,4],\n",
    "             3:[5],\n",
    "             4:[5,6],\n",
    "             5:[7],\n",
    "             6:[8],\n",
    "             7:[8],\n",
    "             8:[9],\n",
    "             9:[],\n",
    "            })\n",
    "test(not d_separation(new_graph, set([3]),set([1]),set([6])))\n",
    "test(d_separation(new_graph, set([3]),set([2]),set([6])))\n",
    "test(not d_separation(new_graph, set([3]),set([9,2]),set([6])))\n",
    "test(not d_separation(new_graph, set([7]),set([5,9]),set([1])))\n",
    "test(d_separation(new_graph, set([7]),set([5]),set([1,6])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5 marks] Task 2.1 - Learning the outcomeSpace from data\n",
    "\n",
    "Learning the outcomeSpace from data should be a relatively simple task. \n",
    "\n",
    "This task is worth 5 marks. Copy, paste and run the test cell bellow. Discount .5 point for each failed case until you reach 0 points.\n",
    "\n",
    "If needed, you can discount up to 2.5 marks in cases such as:\n",
    "1. It wasn't easy to run the test code since it required a code adaptation of some sort.\n",
    "2. The code looks very unorganised or long.\n",
    "3. The code takes overly long to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5 marks] Task 2.2 - Learning the Bayes net parameters from data\n",
    "\n",
    "This task should also be quite simple, given the tutorial code. \n",
    "\n",
    "This task is worth 5 marks. Copy, paste and run the test cell bellow. We have 5 test cases, assign 1 mark for each one.\n",
    "\n",
    "Based on the students' comments in the forum, we may have some issues with running time here. \n",
    "\n",
    "If needed, you can discount up to 2.5 marks in cases such as:\n",
    "1. It wasn't easy to run the test code since it required a code adaptation of some sort.\n",
    "2. The code looks excessively unorganised or long.\n",
    "3. The code takes too long to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1: Testing learn_outcome_space()\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Deduct 1 mark for each test case that doesn't pass above\n",
      "\n",
      "2.2: Testing parameter learning:\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# Test code to copy  #\n",
    "######################\n",
    "\n",
    "\n",
    "### Testing outcome space function\n",
    "print(\"2.1: Testing learn_outcome_space()\")\n",
    "\n",
    "restricted_data = data.head()\n",
    "outcomeSpaceTest = learn_outcome_space(restricted_data)\n",
    "\n",
    "true_outspace = {'BreastDensity': ('high', 'medium', 'low'), 'Location': ('LolwOutQuad', 'UpOutQuad', 'UpInQuad', 'LowInQuad'), 'Age': ('35-49', '50-74', '>75', '<35'), 'BC': ('No', 'Invasive'), 'Mass': ('No', 'Benign', 'Malign'), 'AD': ('No',), 'MC': ('No', 'Yes'), 'Size': ('<1cm', '1-3cm', '>3cm'), 'Shape': ('Other', 'Oval', 'Round'), 'FibrTissueDev': ('No', 'Yes'), 'SkinRetract': ('No', 'Yes'), 'NippleDischarge': ('No', 'Yes'), 'Spiculation': ('No', 'Yes'), 'Margin': ('Well-defined', 'Ill-defined')}\n",
    "test(set(list(true_outspace)) == set(list(outcomeSpaceTest)))\n",
    "test(len(true_outspace) == len(outcomeSpaceTest))\n",
    "for var in true_outspace:\n",
    "    out = outcomeSpaceTest[var]\n",
    "    truth = true_outspace[var]\n",
    "    test(len(out) == len(truth) and set(out) == set(truth))\n",
    "print(\"Deduct 1 mark for each test case that doesn't pass above\")\n",
    "\n",
    "##########################\n",
    "print()\n",
    "\n",
    "print(\"2.2: Testing parameter learning:\")\n",
    "model = BayesNet(G, outcomeSpace=outcomeSpace)\n",
    "\n",
    "model.learn_parameters(data, alpha=1)\n",
    "prob_tables = model.factors\n",
    "\n",
    "test(abs(prob_tables['Age'][('50-74',)] - 0.5001999600079984) < 0.0001)\n",
    "test(abs(prob_tables['Location'][('LolwOutQuad',)] - 0.2510997800439912) < 0.0001)\n",
    "\n",
    "entry_dict = dict(zip(('Spiculation', 'Mass', 'Margin'),('No', 'No', 'Well-defined')))\n",
    "entry = tuple([entry_dict[var] for var in prob_tables['Margin'].domain])\n",
    "test(abs(prob_tables['Margin'][entry] - 0.9998725952350618) < 0.0001)\n",
    "\n",
    "entry_dict = dict(zip(('Age', 'Location', 'BC'),('35-49', 'LolwOutQuad', 'No')))\n",
    "entry = tuple([entry_dict[var] for var in prob_tables['BC'].domain])\n",
    "test(abs(prob_tables['BC'][entry] - 0.7616707616707616) < 0.0001)\n",
    "\n",
    "entry_dict = dict(zip(('Spiculation', 'Mass', 'Margin'),('Yes', 'Malign', 'Ill-defined')))\n",
    "entry = tuple([entry_dict[var] for var in prob_tables['Margin'].domain])\n",
    "test(abs(prob_tables['Margin'][entry] - 0.9439746300211417) < 0.0001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [15 marks] Task 3.1 - Bayes net classification\n",
    "\n",
    "This task is worth 15 points. Our test code only checks the expected accuracy for different \"class\" attributes. If the test cases fail, you still need to look at the code. If the reported accuracy is too low or too high, it is indicative of a possible error. \n",
    "\n",
    "Split the 15 points into 2 main criteria:\n",
    "\n",
    "1. [7.5 points] The code correctly assesses the Bayes net using a set of instances.\n",
    "2. [7.5 points] The code correctly uses the Markov blanket to compute the most likely class of each instance.\n",
    "\n",
    "If needed, you can discount up to 5 marks in cases such as:\n",
    "1. It wasn't easy to run the test code since it required a code adaptation of some sort.\n",
    "2. The code looks excessively unorganised or long."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5 marks] Task 3.2 - Bayes net assessment via cross-validation\n",
    "\n",
    "This task is worth 5 points. Our test code is also limited in this case. So, it is essential that you carefully check the assignment code. The test code will test for an expected accuracy, standard deviation and runtime. However, even if the test cases fail, you need to inspect the source code.\n",
    "\n",
    "Assess if the code correctly assesses the Bayes net using cross-validation. The dataset is correctly split into train and test samples.\n",
    "\n",
    "If needed, you can discount up to 2.5 marks in cases such as:\n",
    "1. It wasn't easy to run the test code since it required a code adaptation of some sort.\n",
    "2. The code looks excessively unorganised or long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If these tests break, try changing the \n",
      "dataset to full sized (and deduct a few marks). Note that the tests are designed for the small dataset\n",
      "3.1 Testing assess_bayes_net\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "\n",
      "Testing that unnecessary factors are not used\n",
      "Passed test case\n",
      "\n",
      "3.2 Testing cross_validation_bayes_net\n",
      "[0.825, 0.85, 0.835, 0.835, 0.845, 0.865, 0.82, 0.82, 0.885, 0.84]\n",
      "Average accuracy: 0.842 ± 0.01951922129594315\n",
      "Time of cv_bayes_net 1.89\n",
      "Passed test case\n",
      "0.842 0.01951922129594315\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# Test code to copy  #\n",
    "######################\n",
    "\n",
    "print(\"If these tests break, try changing the \\ndataset to full sized (and deduct a few marks). Note that the tests are designed for the small dataset\")\n",
    "small_data = data.head(2000)\n",
    "\n",
    "model = BayesNet(G, outcomeSpace)\n",
    "model.learn_parameters(small_data, alpha=1)\n",
    "\n",
    "print(\"3.1 Testing assess_bayes_net\")\n",
    "acc = assess_bayes_net(model, small_data, 'BC')\n",
    "test(abs(acc-0.84225) < 0.001)\n",
    "acc = assess_bayes_net(model, small_data, 'FibrTissueDev')\n",
    "test(abs(acc-0.8355) < 0.001)\n",
    "acc = assess_bayes_net(model, small_data, 'Location')\n",
    "test(abs(acc-0.294) < 0.001)\n",
    "print()\n",
    "\n",
    "print(\"Testing that unnecessary factors are not used\")\n",
    "# Confirm that they are not using the irrelevant \"BreastDensity\" table\n",
    "# check that they are only using tables in the markov blanket, which are the tables of children and parents.\n",
    "try:\n",
    "    if \"BreastDensity\" in model.factors:\n",
    "        del model.factors[\"BreastDensity\"]\n",
    "    assess_bayes_net(model, small_data, 'BC')\n",
    "    print(\"Passed test case\")\n",
    "except:\n",
    "    print(\"Failed test case\")\n",
    "print()\n",
    "\n",
    "print(\"3.2 Testing cross_validation_bayes_net\")\n",
    "import time\n",
    "s = time.time()\n",
    "acc, stddev = cross_validation_bayes_net(small_data, 'BC')\n",
    "print(f\"Average accuracy: {acc} ± {stddev}\")\n",
    "e = time.time()\n",
    "print(\"Time of cv_bayes_net\", round(e-s,2))\n",
    "test(abs(acc-0.831) < 0.01) # !!! This was changed from 0.841, should be 83\n",
    "print(acc, stddev)\n",
    "test(abs(stddev - 0.02) < 0.015)\n",
    "test(stddev > 0)\n",
    "test(e-s < 5)\n",
    "test(e-s < 10)\n",
    "test(e-s < 30)\n",
    "# check that they are correctly doing 10-fold CV, using separate test and train sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [7 marks] Task 4.1 - Assess naive Bayes classification\n",
    "\n",
    "This task is worth 7 points. We created a straightforward test case to assess if the students have coded this function correctly. One critical remark is that they should use log-probabilities in this function. Therefore, we need to inspect the code to check for this part of the implementation. \n",
    "\n",
    "Technical difficulty is that some students may decide to code the entire project with log-probabilities. In this case, they can simply reuse the function assess_bayes_net. There is no problem with this, and you should assign full marks in this case.\n",
    "\n",
    "If the students did not use log-probability assign a maximum of 2 marks.\n",
    "\n",
    "If needed, you can discount up to 2.5 marks in cases such as:\n",
    "1. It wasn't easy to run the test code since it required a code adaptation of some sort.\n",
    "2. The code looks excessively unorganised or long."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [3 marks] Task 4.2 - Naive bayes cross validation\n",
    "\n",
    "This task is also worth 3 marks. It should be straightforward given Task 3.2.\n",
    "\n",
    "Again, our test code is also limited in this case. So, check the assignment code. The test code will test for an expected accuracy, standard deviation and runtime. \n",
    "\n",
    "Assess if the code correctly assesses the naive Bayes classifier using cross-validation. The dataset is correctly split into train and test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If these tests break, try changing the \n",
      "dataset to full sized (and deduct several marks).\n",
      "Note that the tests are designed for the small dataset\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Time of cv_naive_bayes: 2.1227502822875977\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "manually check that the student used log probabilities\n",
      "Tests complete\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# Test code to copy  #\n",
    "######################\n",
    "print(\"4.1\")\n",
    "### -------- Initialize model -----------\n",
    "def learn_naive_bayes_structure(data, class_var):\n",
    "    # create graph\n",
    "    var_names = [key for key in data]\n",
    "    graph = dict([(v,[]) for v in var_names])\n",
    "    var_names.remove(class_var)\n",
    "    for var in var_names:\n",
    "        graph[class_var].append(var)\n",
    "    return Graph(graph)\n",
    "\n",
    "graph = learn_naive_bayes_structure(data, 'BC')\n",
    "model = BayesNet(graph, outcomeSpace)\n",
    "# ----------------------------------------\n",
    "\n",
    "print(\"If these tests break, try changing the \\ndataset to full sized (and deduct several marks).\\nNote that the tests are designed for the small dataset\")\n",
    "small_data = data.head(2000)\n",
    "\n",
    "# Testing basic assess\n",
    "model.learn_parameters(data)\n",
    "acc = assess_naive_bayes(model, small_data, 'BC')\n",
    "# Confirm accuracy\n",
    "test(abs(acc-0.7885)<0.001)\n",
    "test(abs(acc-0.7885)<0.001)\n",
    "test(abs(acc-0.7885)<0.001)\n",
    "\n",
    "\n",
    "\n",
    "# Testing cross_validation\n",
    "print(\"4.2:\")\n",
    "import time\n",
    "s = time.time()\n",
    "acc, stddev = cross_validation_naive_bayes(small_data, 'BC')\n",
    "e = time.time()\n",
    "print(f\"Time of cv_naive_bayes: {e-s}\")\n",
    "\n",
    "\n",
    "# Testing efficiency\n",
    "test(e-s < 5)\n",
    "test(e-s < 7)\n",
    "test(e-s < 12)\n",
    "test(abs(acc-0.7885) < 0.01)\n",
    "test(stddev > 0 and stddev < 0.03)\n",
    "\n",
    "acc, stddev = cross_validation_naive_bayes(small_data, 'MC', 3)\n",
    "test(abs(acc - 0.86) < 0.05) # !!! This might fail if using randomised 10-fold CV\n",
    "\n",
    "acc, stddev = cross_validation_naive_bayes(small_data, 'Location', 8)\n",
    "test(abs(acc - 0.26) < 0.03)\n",
    "\n",
    "# Testing log probabilities\n",
    "print(\"manually check that the student used log probabilities\")\n",
    "\n",
    "print(\"Tests complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [15 marks] Task 5.1 - Learn TAN structure\n",
    "\n",
    "This task is worth 15 marks. The test code has two parts—the first checks for efficiency and the second for a correct TAN graph structure.\n",
    "\n",
    "Split the 15 points into 2 main criteria:\n",
    "\n",
    "1. [5 points] The code efficiently learns the TAN structure.\n",
    "2. [10 points] The code correctly learns the TAN structure.\n",
    "\n",
    "If needed, you can discount up to 5 marks in cases such as:\n",
    "1. It wasn't easy to run the test code since it required a code adaptation of some sort.\n",
    "2. The code looks excessively unorganised or long."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5 marks] Task 5.2 - TAN assessment via cross-validation\n",
    "\n",
    "This task is worth 5 points. Our test code is also limited in this case. So, it is essential that you carefully check the assignment code. The test code will test for an expected accuracy, standard deviation and runtime. However, even if the test cases fail, you need to inspect the source code.\n",
    "\n",
    "Assess if the code correctly assesses the TAN classifier using cross-validation. The dataset is correctly split into train and test samples.\n",
    "\n",
    "If needed, you can discount up to 2.5 marks in cases such as:\n",
    "1. It wasn't easy to run the test code since it required a code adaptation of some sort.\n",
    "2. The code looks excessively unorganised or long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.1\n",
      "Testing tan structure learning on full dataset\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-52086d428b37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"5.1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Testing tan structure learning on full dataset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mtan_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn_tan_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'BC'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# Test code to copy  #\n",
    "######################\n",
    "\n",
    "print(\"5.1\")\n",
    "print(\"Testing tan structure learning on full dataset\")\n",
    "s = time.time()\n",
    "tan_graph = learn_tan_structure(data.head(2000), 'BC')\n",
    "e = time.time()\n",
    "\n",
    "test(e-s < 5)\n",
    "test(e-s < 15)\n",
    "\n",
    "print(\"Checking accuracy\")\n",
    "# Do initial check of accuracy\n",
    "model = BayesNet(tan_graph, outcomeSpace)\n",
    "model.learn_parameters(data.head(2000))\n",
    "acc = assess_bayes_net(model, data.head(2000), 'BC') \n",
    "print(acc)\n",
    "test(abs(acc - 0.8343) < 0.01)\n",
    "\n",
    "# Check that the graph has the correct number of edges\n",
    "sum_edges = 0\n",
    "for node, children in tan_graph.adj_list.items():\n",
    "    if node != 'BC':\n",
    "        sum_edges += len(children)\n",
    "test(sum_edges == len(tan_graph)-2) #number of edges counted in the tree is num nodes in tree - 1 (which is nodes in graph-2 since BC doesn't count)\n",
    "\n",
    "# Check that each node has at most 2 parents\n",
    "GT = dict((v, []) for v in tan_graph)\n",
    "for v in tan_graph:\n",
    "    for w in tan_graph.children(v):\n",
    "        GT[w].append(v)\n",
    "less_than_two_parents = True\n",
    "for node in GT:\n",
    "    if(len(GT[node])>2):\n",
    "        less_than_two_parents = False\n",
    "test(less_than_two_parents)\n",
    "\n",
    "print(\"Testing structure learning on lecture dataset\")\n",
    "\n",
    "# lecture dataset\n",
    "data2 = {}\n",
    "data2['A1'] = [1,1,1,0,1,1,1,0,0,1]\n",
    "data2['A2'] = [1,0,0,1,1,0,1,0,1,1]\n",
    "data2['A3'] = [0,1,1,1,1,1,0,0,1,1]\n",
    "data2['A4'] = [1,1,1,1,0,1,0,1,1,0]\n",
    "data2['C']  = [0,1,1,1,0,1,0,0,1,0]\n",
    "outcomeSpace2 = {\n",
    "    'A1':(0,1),\n",
    "    'A2':(0,1),\n",
    "    'A3':(0,1),\n",
    "    'A4':(0,1),\n",
    "    'C':(0,1),\n",
    "    }\n",
    "data2 = pd.DataFrame.from_dict(data2)\n",
    "graph2 = learn_tan_structure(data2, 'C')\n",
    "graph2.show()\n",
    "test('A2' in graph2.children('A1') or 'A1' in graph2.children('A2'))\n",
    "# !!! The following line was changed to include the second correct answer\n",
    "test('A4' in graph2.children('A2') or 'A2' in graph2.children('A4') or 'A4' in graph2.children('A1') or 'A1' in graph2.children('A4'))\n",
    "test('A3' in graph2.children('A4') or 'A4' in graph2.children('A3'))\n",
    "\n",
    "print()\n",
    "print(\"5.2:\")\n",
    "print(\"Testing efficiency of cross validation\")\n",
    "small_data = data.head(2000)\n",
    "s = time.time()\n",
    "acc, stddev = cross_validation_tan(small_data, 'BC')\n",
    "e = time.time()\n",
    "test(e-s < 10)\n",
    "test(e-s < 20)\n",
    "test(e-s < 30)\n",
    "\n",
    "print(\"Testing accuracy of cross validation\")\n",
    "test(abs(acc - 0.84195) < 0.01)\n",
    "test(stddev > 0)\n",
    "\n",
    "acc, stddev = cross_validation_tan(small_data, 'MC', 6)\n",
    "test(abs(acc - 0.79) < 0.05) # !!! another fix\n",
    "\n",
    "acc, stddev = cross_validation_tan(small_data, 'Location', 8)\n",
    "test(abs(acc - 0.30) < 0.05)\n",
    "\n",
    "\n",
    "print(\"time of cv_tan: \",e-s)\n",
    "print(\"Tests Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [20 marks] Task 6 - Report\n",
    "\n",
    "This is the open-ended part of this assignment. It is worth 20 marks, and it has a limit of 500 words. It is not necessary to count the number of words. We will penalize only reports that are clearly overlength.\n",
    "\n",
    "The assessment criteria are the following:\n",
    "1. [5 marks] The report is well-written and well-organized.\n",
    "2. [10 marks] The report provides a summary of the students’ ﬁndings, reporting the accuracy of each algorithm and comparing the algorithms.\n",
    "3. [5 marks] The report discusses the complexity of each implemented algorithm.\n",
    "\n",
    "If the report is clearly overlength, then penalize it with -5 Marks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
