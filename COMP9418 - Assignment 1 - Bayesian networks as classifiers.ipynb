{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP9418 - Assignment 1 - Bayesian Networks as Classifiers\n",
    "\n",
    "## UNSW Sydney, September 2021\n",
    "\n",
    "- Dezhao Chen - z5302273\n",
    "- Ziqiao Ringgold Lin - z5324329"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "**Submission deadline:** Sunday, 17th October 2021, at 18:00:00.\n",
    "\n",
    "**Late Submission Policy:** The penalty is set at 20% per late day. This is ceiling penalty, so if a group is marked 60/100 and they submitted two days late, they still get 60/100.\n",
    "\n",
    "**Form of Submission:** This is a group assignment. Each group can have up to **two** students. **Only one member of the group should submit the assignment**.\n",
    "\n",
    "You can reuse any piece of source code developed in the tutorials.\n",
    "\n",
    "Submit your files using give. On a CSE Linux machine, type the following on the command-line:\n",
    "\n",
    "``$ give cs9418 ass1 solution.zip``\n",
    "\n",
    "Alternative, you can submit your solution via [WebCMS](https://webcms3.cse.unsw.edu.au/COMP9418/21T3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical prerequisites\n",
    "\n",
    "These are the libraries your are allowed to use. No other libraries will be accepted. Make sure you are using Python 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allowed libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import heapq as pq\n",
    "import matplotlib as mp\n",
    "import math\n",
    "from itertools import product, combinations\n",
    "from graphviz import Digraph\n",
    "from tabulate import tabulate\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the python files we developed in tutorials, or any other code from the tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DiscreteFactors import Factor\n",
    "from Graph import Graph\n",
    "from BayesNet import BayesNet            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial task - Initialise graph\n",
    "\n",
    "Create a graph ``G`` that represents the following network by filling in the edge lists.\n",
    "![Bayes Net](BayesNet.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Graph({\n",
    "    \"BreastDensity\" : [\"Mass\"],\n",
    "    \"Location\" : [\"BC\"],\n",
    "    \"Age\" : [\"BC\"],\n",
    "    \"BC\" : [\"Metastasis\",\"MC\",\"SkinRetract\",\"NippleDischarge\",\"AD\",\"Mass\"],\n",
    "    \"Mass\" : [\"Size\",\"Shape\",\"Margin\"],\n",
    "    \"AD\" : [\"FibrTissueDev\"],\n",
    "    \"Metastasis\" : [\"LymphNodes\"],\n",
    "    \"MC\" : [],\n",
    "    \"Size\" : [],\n",
    "    \"Shape\" : [],\n",
    "    \"FibrTissueDev\" : [\"SkinRetract\",\"NippleDischarge\",\"Spiculation\"],\n",
    "    \"LymphNodes\" : [],\n",
    "    \"SkinRetract\" : [],\n",
    "    \"NippleDischarge\" : [],\n",
    "    \"Spiculation\" : [\"Margin\"],\n",
    "    \"Margin\" : [],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "with open('bc.csv') as file:\n",
    "    data = pd.read_csv(file)\n",
    "\n",
    "#remove 2 variables from data (because we are pretending we don't know this information)\n",
    "if 'Metastasis' in data:\n",
    "    del data['Metastasis']\n",
    "if 'LymphNodes' in data:\n",
    "    del data['LymphNodes']\n",
    "\n",
    "# remove same 2 nodes from graph\n",
    "G.remove_node('Metastasis')\n",
    "G.remove_node('LymphNodes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [20 Marks] Task 1 - Efficient d-separation test\n",
    "\n",
    "Implement the efficient version of the d-separation algorithm in a function ``d_separation(G, X, Z, Y)`` that return a boolean: ``True`` if **X** is d-separated from **Y** given **Z** in the graph $G$ and ``False`` otherwise.\n",
    "\n",
    "* **X**,**Y** and **Z** are python sets, each containing a set of variable names. \n",
    "* Variable names may be strings or integers, and can be assumed to be nodes of the graph $G$. \n",
    "* $G$ is a directed graph object as defined in tutorial 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_separation(G, X, Z, Y):\n",
    "    '''\n",
    "    Arguments:\n",
    "    G:   is an object of type Graph (the class you developed in tutorial 1)\n",
    "    X,Z and Y:  are python `set` objects.\n",
    "    '''\n",
    "    # Step 0: Make a deep copy of the gragh G in case we need to reuse the same graph later\n",
    "    G_dict = copy.deepcopy(G.adj_list)\n",
    "    G_copy = Graph(G_dict)\n",
    "\n",
    "    # Step 1: Keep deleting any leaf nodes from G if it's not in X∪Y∪Z\n",
    "    set_XYZ = (X.union(Y)).union(Z)\n",
    "    while True:\n",
    "        deletable_leafs = []\n",
    "        for node in G_copy.adj_list.keys():\n",
    "            # Get all deletable leaves for current G\n",
    "            if node not in set_XYZ and len(G_copy.adj_list[node]) == 0:\n",
    "                deletable_leafs.append(node)\n",
    "        if len(deletable_leafs) == 0:\n",
    "            # Stop the leaf deletion after no more isolated leaves found\n",
    "            break\n",
    "        else:\n",
    "            # Remove the deletable leaves from G in this round\n",
    "            for node in deletable_leafs:\n",
    "                G_copy.remove_node(node)\n",
    "    # print(\"After Step 1:\", G_copy.adj_list)\n",
    "\n",
    "    # Step 2: Remove any outgoing edges from node(s) Z\n",
    "    for node in Z:\n",
    "        G_copy.adj_list[node] = []\n",
    "    # print(\"After Step 2:\", G_copy.adj_list)\n",
    "\n",
    "    # Step 3: Make current G undirected\n",
    "    for key in G_copy.adj_list.keys():\n",
    "        for node in G_copy.adj_list[key]:\n",
    "            if key not in  G_copy.adj_list[node]:\n",
    "                G_copy.adj_list[node].append(key)\n",
    "    # print(\"After Step 3:\", G_copy.adj_list)\n",
    "\n",
    "    # Step 4: Check the connectivity from X to Y in current graph G\n",
    "    overall_connected = False\n",
    "    for node in X:\n",
    "        connectivity_color_map = G_copy.dfs(node)\n",
    "        # print(connectivity_color_map)\n",
    "        for dest in Y:\n",
    "            if connectivity_color_map[dest] == 'black' or connectivity_color_map[dest] == 'grey':\n",
    "                # black or grey indicates this node is found in DFS search for at least once\n",
    "                overall_connected = True\n",
    "    return not overall_connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Custom tests\n",
    "d_separation(G, set(['Age']), set(['BC', 'MC']), set(['AD']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed test case\n",
      "Passed test case\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "## Note: More hidden tests will be used. You should make more tests yourself.\n",
    "\n",
    "def test(statement):\n",
    "    if statement:\n",
    "        print(\"Passed test case\")\n",
    "    else:\n",
    "        print(\"Failed test case\")\n",
    "        \n",
    "test(d_separation(G, set(['Age']), set(['BC']), set(['AD'])))\n",
    "test(not d_separation(G, set(['Spiculation','SkinRetract']), set(['MC', 'Size']), set(['Age'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [10 Marks] Task 2 - Estimate Bayesian Network parameters from data\n",
    "\n",
    "Implement a function ``learn_outcome_space(data)`` that learns the outcome space (the valid values for each variable) from the pandas dataframe ``data`` and returns a dictionary ``outcomeSpace`` with these values.\n",
    "\n",
    "Implement a method ``model.learn_parameters(data, alpha=1)`` that learns the parameters of the Bayesian Network `model`. This function should do the same as the ``learn_parameters`` function from tutorials, but it should also implement laplacian smoothing with parameter $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for learn_outcome_space(data) in one or more cells here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_outcome_space(data):\n",
    "    '''\n",
    "    Arguments:\n",
    "        data - A pandas dataframe\n",
    "    Returns: \n",
    "        outcomeSpace - A dictionary. e.g. {'A':('True', 'False'), 'B':('up','down','left'), 'C':(1,2,3,4)}\n",
    "    '''\n",
    "    outcomeSpace = {}\n",
    "    for col in data.columns:\n",
    "        outcomeSpace[col] = tuple(data[col].unique())\n",
    "    return outcomeSpace\n",
    "\n",
    "\n",
    "outcomeSpace = learn_outcome_space(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed test case\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "outcomeSpace = learn_outcome_space(data)\n",
    "\n",
    "outcomes = outcomeSpace['BreastDensity']\n",
    "answer = ('high', 'medium', 'low')\n",
    "test(len(outcomes) == len(answer) and set(outcomes) == set(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for learnParameters in one or more cells here\n",
    "def allEqualThisIndex(dict_of_arrays, **fixed_vars):\n",
    "    # base index is a boolean vector, everywhere true\n",
    "    first_array = dict_of_arrays[list(dict_of_arrays.keys())[0]]\n",
    "    index = np.ones_like(first_array, dtype=np.bool_)\n",
    "    for var_name, var_val in fixed_vars.items():\n",
    "        index = index & (np.asarray(dict_of_arrays[var_name])==var_val)\n",
    "    return index\n",
    "\n",
    "def estimateFactor(data, var_name, parent_names, outcomeSpace,alpha):\n",
    "    var_outcomes = outcomeSpace[var_name]\n",
    "    parent_outcomes = [outcomeSpace[var] for var in (parent_names)]\n",
    "    # cartesian product to generate a table of all possible outcomes\n",
    "    all_parent_combinations = product(*parent_outcomes)\n",
    "\n",
    "    f = Factor(list(parent_names)+[var_name], outcomeSpace)\n",
    "    \n",
    "    for i, parent_combination in enumerate(all_parent_combinations):\n",
    "        parent_vars = dict(zip(parent_names, parent_combination))\n",
    "        parent_index = allEqualThisIndex(data, **parent_vars)\n",
    "        for var_outcome in var_outcomes:\n",
    "            var_index = (np.asarray(data[var_name])==var_outcome)\n",
    "            f[tuple(list(parent_combination)+[var_outcome])] = ((var_index & parent_index).sum()+alpha)/(parent_index.sum()+alpha*len(var_outcomes))\n",
    "            \n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesNet(BayesNet):\n",
    "    def learn_parameters(self, data, alpha=1):\n",
    "        graphT = self.graph.transpose()\n",
    "        for node, parents in graphT.adj_list.items():\n",
    "            f = estimateFactor(data, node, parents, self.outcomeSpace,alpha)\n",
    "            self.factors[node] = f\n",
    "\n",
    "model = BayesNet(G,outcomeSpace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed test case\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "model.learn_parameters(data, alpha=1)\n",
    "\n",
    "test(model.factors['Age']['35-49'] == 0.248000399920016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [20 Marks] Task 3 - Bayesian Network Classification\n",
    "\n",
    "Design a new function ``assess_bayes_net(model, dataframe, var)`` that uses the test cases in ``dataframe`` to assess the performance of the Bayesian network at classifying the variable `var`. Implement the efficient classification procedure discussed in the lectures (make sure you understand what a Markov Blanket is). Such a function should return the classifier accuracy. \n",
    "\n",
    " * ``var`` is the name of the variable you are predicting, using the values of all the other variables. \n",
    " \n",
    "If you like, you can add new functions to the BayesNet class, or write helper functions to help solve the above task.\n",
    "\n",
    "Using another function called `cross_validation_bayes_net`, compute and report the average accuracy over the ten cross-validation runs as well as the standard deviation. A scaffold for this function is provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for assess_bayes_net in one or more cells here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomeSpace = learn_outcome_space(data)\n",
    "model = BayesNet(G,outcomeSpace)\n",
    "model.learn_parameters(data, alpha=1)\n",
    "\n",
    "def get_parents(G):\n",
    "    '''\n",
    "    Create a parent nodes dict list for input graph and return it\n",
    "    '''\n",
    "    graph_parents_list={}\n",
    "    for node in G:\n",
    "        graph_parents_list[node]=[]\n",
    "    for parent_node in G:\n",
    "        for child_node in G[parent_node]:\n",
    "            graph_parents_list[child_node].append(parent_node)\n",
    "    return graph_parents_list\n",
    "\n",
    "def get_markov_blanket(model: BayesNet, var: str):\n",
    "    '''\n",
    "    1. Find all parents\n",
    "    2. Find all children\n",
    "    3. Find all spouses\n",
    "    '''\n",
    "    markov_blanket = []\n",
    "    graph = model.graph.adj_list\n",
    "    # add children\n",
    "    markov_blanket = markov_blanket + graph[var]\n",
    "    # add parent\n",
    "    graph_parents_list = get_parents(graph)\n",
    "    markov_blanket = markov_blanket + graph_parents_list[var]\n",
    "    \n",
    "    # add all spouses\n",
    "    for node in graph[var]:\n",
    "        markov_blanket = markov_blanket + graph_parents_list[node]\n",
    "    markov_blanket = list(dict.fromkeys(markov_blanket))\n",
    "    \n",
    "    # Make sure both verions of markov blankets are returned\n",
    "    markov_blanket_without_var = copy.deepcopy(markov_blanket)\n",
    "    if var in markov_blanket:\n",
    "        markov_blanket_without_var.remove(var)\n",
    "    else:\n",
    "        markov_blanket.append(var)\n",
    "\n",
    "    return markov_blanket, markov_blanket_without_var\n",
    "\n",
    "def get_related_table(model: BayesNet, var_space: list):\n",
    "    '''\n",
    "    Get the joint table of a given bayes net model of a given variable space\n",
    "    '''\n",
    "    all_table = model.factors\n",
    "    table = all_table[var_space[0]]\n",
    "    for i in range(1, len(var_space)):\n",
    "        table = table.join(all_table[var_space[i]])\n",
    "    return table\n",
    "\n",
    "def assess_bayes_net(model, dataframe, var='BC'):\n",
    "    '''\n",
    "    Test the accuracy given trained model by using the test dataframe\n",
    "    '''\n",
    "    # Get the probability table of all the variables in 'var' markov blanket\n",
    "    markov_blanket, markov_blanket_without_var = get_markov_blanket(model, var)\n",
    "    # markov_blanket_table = get_related_table(model, markov_blanket)\n",
    "    related_test_table = dataframe[markov_blanket]\n",
    "    correct_amount = 0\n",
    "    total_amount = 0\n",
    "    print(related_test_table.shape)\n",
    "    for row_index, row_data in related_test_table.iterrows():\n",
    "        var_value_actual = row_data.pop(var)\n",
    "        row_data_dict = dict(row_data)\n",
    "        query_result = model.query([var], **row_data_dict)\n",
    "        query_result_values = query_result.table\n",
    "        # print(query_result_values)\n",
    "        var_possible_values = model.outcomeSpace[var]\n",
    "        # print(var_possible_values)\n",
    "        if len(query_result_values) != len(var_possible_values):\n",
    "            print(\"Warning: query table not the same with actual values:\", query_result_values, var_possible_values)\n",
    "        possibility_max = np.max(query_result_values)\n",
    "        possibility_max_index = np.argmax(possibility_max)\n",
    "        # print(\"Guessed index: \", possibility_max_index)\n",
    "        var_value_prediced = var_possible_values[possibility_max_index]\n",
    "        # print(\"Guessed value: \", var_value_prediced)\n",
    "        \n",
    "        if var_value_prediced == var_value_actual:\n",
    "            correct_amount += 1\n",
    "        total_amount += 1\n",
    "        # print(possibility_max, var_value_prediced)\n",
    "        # break\n",
    "    accuracy = correct_amount * 1.0 / (total_amount * 1.0)\n",
    "    print(accuracy)\n",
    "    return accuracy\n",
    "\n",
    "# def cross_validation_bayes_net(dataframe, var='BC', k=10):\n",
    "#     accuracy_list = []\n",
    "#     for i in range(k):\n",
    "#         # split dataset into train and test\n",
    "#         ...\n",
    "        \n",
    "#         # train a model\n",
    "#         ...\n",
    "        \n",
    "#         # test the model with assess_bayes_net\n",
    "#         acc = ...\n",
    "        \n",
    "#         accuracy_list.append(acc)\n",
    "#     return np.mean(accuracy_list), np.std(accuracy_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Custom tests\n",
    "print(assess_bayes_net(model, data, var='BC'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "acc, stddev = cross_validation_bayes_net(data, 'BC', 10)\n",
    "test(abs(acc - 0.85) < 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [10 Marks] Task 4 - Naïve Bayes Classification\n",
    "\n",
    "Design a new function ``assess_naive_bayes(model, data, var)`` to classify and assess the test cases in ``data``. To classify each example, use the log probability trick discussed in the lectures. Do $k$-fold cross-validation with the `cross_validation_naive_bayes(data, var, k)` function, same as above, and return ``acc`` and ``stddev``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for assess_naive_bayes(model, data, var) in one or more cells here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "\n",
    "\n",
    "def assess_naive_bayes(model, dataframe, var='BC'):\n",
    "    ...\n",
    "    return accuracy\n",
    "    \n",
    "def cross_validation_naive_bayes(dataframe, var='BC', k=10):\n",
    "    accuracy_list = []\n",
    "    for i in range(k):\n",
    "        # split dataset into train and test\n",
    "        ...\n",
    "        \n",
    "        # create and train a model\n",
    "        ...\n",
    "        \n",
    "        # test the model with assess_naive_bayes\n",
    "        acc = ...\n",
    "        \n",
    "        accuracy_list.append(acc)\n",
    "    return np.mean(accuracy_list), np.std(accuracy_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "acc, stddev = cross_validation_naive_bayes(data, 'BC')\n",
    "test(abs(acc - 0.80) < 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [20 Marks] Task 5 - Tree-augmented Naïve Bayes Classification\n",
    "\n",
    "Similarly to the previous task, implement a Tree-augmented Naïve Bayes (TAN) classifier and evaluate your implementation in the breast cancer dataset. Design a function ``learn_tan_structure(data, class_var)`` to learn the TAN structure (graph) from ``data`` and return such a structure. Scaffolds for required functions are given below. Implement other helper functions as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for learn_tan_structure(data) in one or more cells here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_tan_structure(data, class_var='BC'):\n",
    "    '''\n",
    "    Arguments:\n",
    "        data: a dataframe\n",
    "        class_var: The variable you will be classifying with this graph structure\n",
    "    Return:\n",
    "        graph: A Graph object\n",
    "    '''\n",
    "    ...\n",
    "    return graph\n",
    "\n",
    "...\n",
    "\n",
    "def cross_validation_tan(data, var='BC', k=10):\n",
    "    ...\n",
    "    return np.mean(accuracy_list), np.std(accuracy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "tan_graph = learn_tan_structure(data)\n",
    "test(len(tan_graph.children('BC')) == len(tan_graph)-1)\n",
    "test('FibrTissueDev' in tan_graph.children('Spiculation') or 'Spiculation' in tan_graph.children('FibrTissueDev'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [20 Marks] Task 6 - Report\n",
    "\n",
    "Write a report (**with less than 500 words**) summarising your findings in this assignment. Your report should address the following:\n",
    "\n",
    "a. Make a summary and discussion of the experimental results. You can analyse your results from different aspects such as accuracy, runtime, coding complexity and independence assumptions. You can use plots to illustrate your results.\n",
    "\n",
    "b. Discuss the time and memory complexity of the implemented algorithms.\n",
    "\n",
    "Use Markdown and Latex to write your report in the Jupyter notebook. Develop some plots using Matplotlib to illustrate your results. Be mindful of the maximum number of words. Please, be concise and objective."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6f8ee94c255eb1f45edb80e83721093c1db1e2ea85447c0854292673b957abb8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
