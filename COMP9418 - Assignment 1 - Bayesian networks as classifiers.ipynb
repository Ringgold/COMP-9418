{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP9418 - Assignment 1 - Bayesian Networks as Classifiers\n",
    "\n",
    "## UNSW Sydney, September 2021\n",
    "\n",
    "- Dezhao Chen - z5302273\n",
    "- Ziqiao Ringgold Lin - z5324329"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "**Submission deadline:** Sunday, 17th October 2021, at 18:00:00.\n",
    "\n",
    "**Late Submission Policy:** The penalty is set at 20% per late day. This is ceiling penalty, so if a group is marked 60/100 and they submitted two days late, they still get 60/100.\n",
    "\n",
    "**Form of Submission:** This is a group assignment. Each group can have up to **two** students. **Only one member of the group should submit the assignment**.\n",
    "\n",
    "You can reuse any piece of source code developed in the tutorials.\n",
    "\n",
    "Submit your files using give. On a CSE Linux machine, type the following on the command-line:\n",
    "\n",
    "``$ give cs9418 ass1 solution.zip``\n",
    "\n",
    "Alternative, you can submit your solution via [WebCMS](https://webcms3.cse.unsw.edu.au/COMP9418/21T3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical prerequisites\n",
    "\n",
    "These are the libraries your are allowed to use. No other libraries will be accepted. Make sure you are using Python 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allowed libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import heapq as pq\n",
    "import matplotlib as mp\n",
    "import math\n",
    "from itertools import product, combinations\n",
    "from graphviz import Digraph\n",
    "from tabulate import tabulate\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the python files we developed in tutorials, or any other code from the tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DiscreteFactors import Factor\n",
    "from Graph import Graph\n",
    "from BayesNet import BayesNet            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial task - Initialise graph\n",
    "\n",
    "Create a graph ``G`` that represents the following network by filling in the edge lists.\n",
    "![Bayes Net](BayesNet.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Graph({\n",
    "    \"BreastDensity\" : [\"Mass\"],\n",
    "    \"Location\" : [\"BC\"],\n",
    "    \"Age\" : [\"BC\"],\n",
    "    \"BC\" : [\"Metastasis\",\"MC\",\"SkinRetract\",\"NippleDischarge\",\"AD\",\"Mass\"],\n",
    "    \"Mass\" : [\"Size\",\"Shape\",\"Margin\"],\n",
    "    \"AD\" : [\"FibrTissueDev\"],\n",
    "    \"Metastasis\" : [\"LymphNodes\"],\n",
    "    \"MC\" : [],\n",
    "    \"Size\" : [],\n",
    "    \"Shape\" : [],\n",
    "    \"FibrTissueDev\" : [\"SkinRetract\",\"NippleDischarge\",\"Spiculation\"],\n",
    "    \"LymphNodes\" : [],\n",
    "    \"SkinRetract\" : [],\n",
    "    \"NippleDischarge\" : [],\n",
    "    \"Spiculation\" : [\"Margin\"],\n",
    "    \"Margin\" : [],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "with open('bc.csv') as file:\n",
    "    data = pd.read_csv(file)\n",
    "\n",
    "#remove 2 variables from data (because we are pretending we don't know this information)\n",
    "if 'Metastasis' in data:\n",
    "    del data['Metastasis']\n",
    "if 'LymphNodes' in data:\n",
    "    del data['LymphNodes']\n",
    "\n",
    "# remove same 2 nodes from graph\n",
    "G.remove_node('Metastasis')\n",
    "G.remove_node('LymphNodes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [20 Marks] Task 1 - Efficient d-separation test\n",
    "\n",
    "Implement the efficient version of the d-separation algorithm in a function ``d_separation(G, X, Z, Y)`` that return a boolean: ``True`` if **X** is d-separated from **Y** given **Z** in the graph $G$ and ``False`` otherwise.\n",
    "\n",
    "* **X**,**Y** and **Z** are python sets, each containing a set of variable names. \n",
    "* Variable names may be strings or integers, and can be assumed to be nodes of the graph $G$. \n",
    "* $G$ is a directed graph object as defined in tutorial 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_separation(G, X, Z, Y):\n",
    "    '''\n",
    "    Arguments:\n",
    "    G:   is an object of type Graph (the class you developed in tutorial 1)\n",
    "    X,Z and Y:  are python `set` objects.\n",
    "    '''\n",
    "    # Step 0: Make a deep copy of the gragh G in case we need to reuse the same graph later\n",
    "    G_dict = copy.deepcopy(G.adj_list)\n",
    "    G_copy = Graph(G_dict)\n",
    "\n",
    "    # Step 1: Keep deleting any leaf nodes from G if it's not in X∪Y∪Z\n",
    "    set_XYZ = (X.union(Y)).union(Z)\n",
    "    while True:\n",
    "        deletable_leafs = []\n",
    "        for node in G_copy.adj_list.keys():\n",
    "            # Get all deletable leaves for current G\n",
    "            if node not in set_XYZ and len(G_copy.adj_list[node]) == 0:\n",
    "                deletable_leafs.append(node)\n",
    "        if len(deletable_leafs) == 0:\n",
    "            # Stop the leaf deletion after no more isolated leaves found\n",
    "            break\n",
    "        else:\n",
    "            # Remove the deletable leaves from G in this round\n",
    "            for node in deletable_leafs:\n",
    "                G_copy.remove_node(node)\n",
    "\n",
    "    # Step 2: Remove any outgoing edges from node(s) Z\n",
    "    for node in Z:\n",
    "        G_copy.adj_list[node] = []\n",
    "\n",
    "    # Step 3: Make current G undirected\n",
    "    for key in G_copy.adj_list.keys():\n",
    "        for node in G_copy.adj_list[key]:\n",
    "            if key not in  G_copy.adj_list[node]:\n",
    "                G_copy.adj_list[node].append(key)\n",
    "\n",
    "    # Step 4: Check the connectivity from X to Y in current graph G\n",
    "    overall_connected = False\n",
    "    for node in X:\n",
    "        connectivity_color_map = G_copy.dfs(node)\n",
    "        for dest in Y:\n",
    "            if connectivity_color_map[dest] == 'black' or connectivity_color_map[dest] == 'grey':\n",
    "                # black or grey indicates this node is found in DFS search for at least once\n",
    "                overall_connected = True\n",
    "    return not overall_connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed test case\n",
      "Passed test case\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "## Note: More hidden tests will be used. You should make more tests yourself.\n",
    "\n",
    "def test(statement):\n",
    "    if statement:\n",
    "        print(\"Passed test case\")\n",
    "    else:\n",
    "        print(\"Failed test case\")\n",
    "        \n",
    "test(d_separation(G, set(['Age']), set(['BC']), set(['AD'])))\n",
    "test(not d_separation(G, set(['Spiculation','SkinRetract']), set(['MC', 'Size']), set(['Age'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [10 Marks] Task 2 - Estimate Bayesian Network parameters from data\n",
    "\n",
    "Implement a function ``learn_outcome_space(data)`` that learns the outcome space (the valid values for each variable) from the pandas dataframe ``data`` and returns a dictionary ``outcomeSpace`` with these values.\n",
    "\n",
    "Implement a method ``model.learn_parameters(data, alpha=1)`` that learns the parameters of the Bayesian Network `model`. This function should do the same as the ``learn_parameters`` function from tutorials, but it should also implement laplacian smoothing with parameter $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for learn_outcome_space(data) in one or more cells here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_outcome_space(data):\n",
    "    '''\n",
    "    Arguments:\n",
    "        data - A pandas dataframe\n",
    "    Returns: \n",
    "        outcomeSpace - A dictionary. e.g. {'A':('True', 'False'), 'B':('up','down','left'), 'C':(1,2,3,4)}\n",
    "    '''\n",
    "    outcomeSpace = {}\n",
    "    for col in data.columns:\n",
    "        outcomeSpace[col] = tuple(data[col].unique())\n",
    "    return outcomeSpace\n",
    "\n",
    "\n",
    "outcomeSpace = learn_outcome_space(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed test case\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "outcomeSpace = learn_outcome_space(data)\n",
    "\n",
    "outcomes = outcomeSpace['BreastDensity']\n",
    "answer = ('high', 'medium', 'low')\n",
    "test(len(outcomes) == len(answer) and set(outcomes) == set(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for learnParameters in one or more cells here\n",
    "def allEqualThisIndex(dict_of_arrays, **fixed_vars):\n",
    "    # base index is a boolean vector, everywhere true\n",
    "    first_array = dict_of_arrays[list(dict_of_arrays.keys())[0]]\n",
    "    index = np.ones_like(first_array, dtype=np.bool_)\n",
    "    for var_name, var_val in fixed_vars.items():\n",
    "        index = index & (np.asarray(dict_of_arrays[var_name])==var_val)\n",
    "    return index\n",
    "\n",
    "def estimateFactor(data, var_name, parent_names, outcomeSpace, alpha):\n",
    "    var_outcomes = outcomeSpace[var_name]\n",
    "    parent_outcomes = [outcomeSpace[var] for var in (parent_names)]\n",
    "    # cartesian product to generate a table of all possible outcomes\n",
    "    all_parent_combinations = product(*parent_outcomes)\n",
    "\n",
    "    f = Factor(list(parent_names) + [var_name], outcomeSpace)\n",
    "\n",
    "    for i, parent_combination in enumerate(all_parent_combinations):\n",
    "        parent_vars = dict(zip(parent_names, parent_combination))\n",
    "        parent_index = allEqualThisIndex(data, **parent_vars)\n",
    "        for var_outcome in var_outcomes:\n",
    "            var_index = (np.asarray(data[var_name]) == var_outcome)\n",
    "            # Laplacian smoothing\n",
    "            # p= (c+alpha)/(N+alpha*|X|)\n",
    "            # tut line: (var_index & parent_index).sum()/parent_index.sum()\n",
    "            # c = (var_index & parent_index).sum()\n",
    "            # N = parent_index.sum()\n",
    "            # we have |X| = len(var_outcomes)\n",
    "            c = (var_index & parent_index).sum()\n",
    "            N = parent_index.sum()\n",
    "            X = len(var_outcomes)\n",
    "            f[tuple(list(parent_combination) + [var_outcome])] = (c + alpha) / (N + alpha * X)\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesNet(BayesNet):\n",
    "    def learn_parameters(self, data, alpha=1):\n",
    "        graphT = self.graph.transpose()\n",
    "        for node, parents in graphT.adj_list.items():\n",
    "            f = estimateFactor(data, node, parents, self.outcomeSpace,alpha)\n",
    "            self.factors[node] = f\n",
    "\n",
    "model = BayesNet(G,outcomeSpace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed test case\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "model.learn_parameters(data, alpha=1)\n",
    "\n",
    "test(model.factors['Age']['35-49'] == 0.248000399920016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [20 Marks] Task 3 - Bayesian Network Classification\n",
    "\n",
    "Design a new function ``assess_bayes_net(model, dataframe, var)`` that uses the test cases in ``dataframe`` to assess the performance of the Bayesian network at classifying the variable `var`. Implement the efficient classification procedure discussed in the lectures (make sure you understand what a Markov Blanket is). Such a function should return the classifier accuracy. \n",
    "\n",
    " * ``var`` is the name of the variable you are predicting, using the values of all the other variables. \n",
    " \n",
    "If you like, you can add new functions to the BayesNet class, or write helper functions to help solve the above task.\n",
    "\n",
    "Using another function called `cross_validation_bayes_net`, compute and report the average accuracy over the ten cross-validation runs as well as the standard deviation. A scaffold for this function is provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for assess_bayes_net in one or more cells here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Here, we create our own query function so that:\n",
    "1. We do not need to join (all of) the variables' prop table every single time when doing query\n",
    "2. We can pass custimized table for query, and prevent using oversized table for small queries\n",
    "'''\n",
    "class BayesNet(BayesNet):\n",
    "    def query_without_self_joint(self, table, q_vars, **q_evi):\n",
    "        \"\"\"\n",
    "        arguments \n",
    "        `table`, the table used for query\n",
    "        `q_vars`, list of variables in query head\n",
    "        `q_evi`, dictionary of evidence in the form of variables names and values\n",
    "\n",
    "        Returns a new NORMALIZED factor will all hidden variables eliminated as evidence set as in q_evi\n",
    "        \"\"\"     \n",
    "        assert isinstance(q_vars,list) or sinstance(q_vars,tuple), \"q_vars should be a list\"\n",
    "        \n",
    "        f = table\n",
    "        \n",
    "        # First, we set the evidence \n",
    "        f = f.evidence(**q_evi)\n",
    "\n",
    "        # Second, we eliminate hidden variables NOT in the query\n",
    "        for var in self.outcomeSpace:\n",
    "            if var not in q_vars:\n",
    "                f = f.marginalize(var)\n",
    "        return f.normalize()\n",
    "\n",
    "def get_parents(G):\n",
    "    '''\n",
    "    Create a parent nodes dict list for input graph and return it\n",
    "    '''\n",
    "    graph_parents_list={}\n",
    "    for node in G:\n",
    "        graph_parents_list[node]=[]\n",
    "    for parent_node in G:\n",
    "        for child_node in G[parent_node]:\n",
    "            graph_parents_list[child_node].append(parent_node)\n",
    "    return graph_parents_list\n",
    "\n",
    "def get_markov_blanket(model: BayesNet, var: str):\n",
    "    '''\n",
    "    1. Find all parents\n",
    "    2. Find all children\n",
    "    3. Find all spouses\n",
    "    '''\n",
    "    markov_blanket = []\n",
    "    graph = model.graph.adj_list\n",
    "    # add children\n",
    "    markov_blanket = markov_blanket + graph[var]\n",
    "    # add parent\n",
    "    graph_parents_list = get_parents(graph)\n",
    "    markov_blanket = markov_blanket + graph_parents_list[var]\n",
    "    \n",
    "    # add all spouses\n",
    "    for node in graph[var]:\n",
    "        markov_blanket = markov_blanket + graph_parents_list[node]\n",
    "    markov_blanket = list(dict.fromkeys(markov_blanket))\n",
    "    \n",
    "    # Make sure both verions of markov blankets are returned\n",
    "    markov_blanket_without_var = copy.deepcopy(markov_blanket)\n",
    "    if var in markov_blanket:\n",
    "        markov_blanket_without_var.remove(var)\n",
    "    else:\n",
    "        markov_blanket.append(var)\n",
    "    return markov_blanket, markov_blanket_without_var\n",
    "\n",
    "def get_related_table(model: BayesNet, var_space: list):\n",
    "    '''\n",
    "    Get the joint table of a given bayes net model of a given variable space\n",
    "    '''\n",
    "    # Check if var space are all having correct var\n",
    "    all_table = model.factors\n",
    "    for var in var_space:\n",
    "        if var not in all_table.keys():\n",
    "            var_space.remove(var)\n",
    "\n",
    "    table = []\n",
    "    if len(var_space) > 0:\n",
    "        table = all_table[var_space[0]]\n",
    "    \n",
    "    if len(var_space) > 1:\n",
    "        for i in range(1, len(var_space)):\n",
    "            table = table.join(all_table[var_space[i]])\n",
    "    return table\n",
    "\n",
    "def assess_bayes_net(model, dataframe, var='BC'):\n",
    "    '''\n",
    "    Test the accuracy given trained model by using the test dataframe\n",
    "    '''\n",
    "    # Get the probability table of all the variables in 'var' markov blanket\n",
    "    markov_blanket, markov_blanket_without_var = get_markov_blanket(model, var)\n",
    "    related_test_table = dataframe[markov_blanket]\n",
    "    correct_amount = 0\n",
    "    total_amount = 0\n",
    "    joint_table = get_related_table(model, markov_blanket)\n",
    "    for row_index, row_data in related_test_table.iterrows():\n",
    "        # Get evidence and actual value of var from the test data\n",
    "        var_value_actual = row_data.pop(var)\n",
    "        row_data_dict = dict(row_data)\n",
    "\n",
    "        # get p(var|evidence) in an array\n",
    "        query_result = model.query_without_self_joint(joint_table, [var], **row_data_dict)\n",
    "        var_possible_values = model.outcomeSpace[var]\n",
    "\n",
    "        # Get predicted value according to the query table result\n",
    "        possibility_max = 0\n",
    "        var_value_prediced = None\n",
    "        for value in var_possible_values:\n",
    "            possibility = query_result[value]\n",
    "            if possibility > possibility_max:\n",
    "                possibility_max = possibility\n",
    "                var_value_prediced = value\n",
    "\n",
    "        # Compare predicted value and actual value of the variable with current evidence\n",
    "        if var_value_prediced == var_value_actual:\n",
    "            correct_amount += 1\n",
    "        total_amount += 1\n",
    "    accuracy = correct_amount/total_amount\n",
    "    return accuracy\n",
    "\n",
    "def cross_validation_bayes_net(dataframe, var='BC', k=10):\n",
    "    accuracy_list = []\n",
    "    outcomeSpace = learn_outcome_space(data)\n",
    "    model = BayesNet(G, outcomeSpace)\n",
    "\n",
    "    for i in range(k):\n",
    "        # split dataset into train and test\n",
    "        length = int(len(dataframe) / k)\n",
    "        data_train = data.drop([e for e in range(i * length, (i + 1) * length)])\n",
    "        data_test = data.loc[i * length:(i + 1) * length - 1]\n",
    "        # train a model\n",
    "        model.learn_parameters(data_train)\n",
    "        \n",
    "        # test the model with assess_bayes_net\n",
    "        acc = assess_bayes_net(model, data_test, var)\n",
    "        accuracy_list.append(acc)\n",
    "    return np.mean(accuracy_list), np.std(accuracy_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed test case\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "acc, stddev = cross_validation_bayes_net(data, 'BC', 10)\n",
    "test(abs(acc - 0.85) < 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [10 Marks] Task 4 - Naïve Bayes Classification\n",
    "\n",
    "Design a new function ``assess_naive_bayes(model, data, var)`` to classify and assess the test cases in ``data``. To classify each example, use the log probability trick discussed in the lectures. Do $k$-fold cross-validation with the `cross_validation_naive_bayes(data, var, k)` function, same as above, and return ``acc`` and ``stddev``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for assess_naive_bayes(model, data, var) in one or more cells here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_naive_bayes(model, dataframe, var='BC'):\n",
    "    correct = 0\n",
    "\n",
    "    for index, single_data in dataframe.iterrows():\n",
    "        plist = dict()\n",
    "        predict = None\n",
    "        for outcome in model.outcomeSpace[var]:\n",
    "            # prior, log(prior)\n",
    "            p_outcome = np.log(model.factors[var][(outcome)])\n",
    "\n",
    "            for node in model.graph.adj_list[var]:\n",
    "                # p = prior*p(A1|C)*p(A2|C)*...*p(An|C)\n",
    "                # log(p) = log(prior*p(A1|C)*p(A2|C)*...*p(An|C))\n",
    "                # log(p) = log(prior)+log(p(A1|C))+log(p(A2|C))+...+log(p(An|C)))\n",
    "                # log(p) <= log(prior) += log(p(Ai|C))\n",
    "                # p_outcome = log(prior)\n",
    "                # p_outcome += log(p(Ai|C))\n",
    "                # factors are all p(Ai|C)\n",
    "                p_outcome += np.log(model.factors[node][(outcome, single_data[node])])\n",
    "\n",
    "            # keep all the p=(C|A)\n",
    "            plist[outcome] = p_outcome\n",
    "        # take the largest p as predict\n",
    "        predict = list(plist.keys())[list(plist.values()).index(max(plist.values()))]\n",
    "\n",
    "        if predict == single_data[var]:\n",
    "            correct += 1\n",
    "    accuracy = correct / len(dataframe)\n",
    "    return accuracy\n",
    "\n",
    "def cross_validation_naive_bayes(dataframe, var='BC', k=10):\n",
    "    # note: the modification of graph and creation of naive bayesian model is in the cv function\n",
    "    # so if test is outside the cv function then the lines of g_nb should be run before running assess_naive_bayes()\n",
    "    accuracy_list = []\n",
    "    outcomeSpace = learn_outcome_space(data)\n",
    "    \n",
    "    # process the graph to make it a naive bayes graph (var to all other nodes)\n",
    "    g_nb = copy.deepcopy(G)\n",
    "    for node in g_nb.adj_list.keys():\n",
    "        g_nb.adj_list[node] = []\n",
    "    g_nb.adj_list[var] = list(g_nb.adj_list.keys())\n",
    "    g_nb.adj_list[var].remove(var)\n",
    "    # create the NBC graph\n",
    "    \n",
    "    for i in range(k):\n",
    "        # split dataset into train and test\n",
    "\n",
    "        length = int(len(dataframe) / k)\n",
    "        data_train = data.drop([e for e in range(i * length, (i + 1) * length)])\n",
    "        data_test = data.loc[i * length:(i + 1) * length - 1]\n",
    "\n",
    "        # create and train a model\n",
    "\n",
    "        nbmodel = BayesNet(g_nb, outcomeSpace)\n",
    "        nbmodel.learn_parameters(data_train)\n",
    "\n",
    "        # test the model with assess_naive_bayes\n",
    "        acc = assess_naive_bayes(nbmodel, data_test)\n",
    "\n",
    "        accuracy_list.append(acc)\n",
    "    return np.mean(accuracy_list), np.std(accuracy_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed test case\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "#g_nb = copy.deepcopy(G)\n",
    "#for node in g_nb.adj_list.keys():\n",
    "#    g_nb.adj_list[node] = []\n",
    "#g_nb.adj_list['BC'] = list(g_nb.adj_list.keys())\n",
    "#g_nb.adj_list['BC'].remove('BC')\n",
    "\n",
    "#nbmodel = BayesNet(g_nb, outcomeSpace)\n",
    "#nbmodel.learn_parameters(data)\n",
    "\n",
    "#acctest = assess_naive_bayes(nbmodel, data)\n",
    "#print(acctest)\n",
    "\n",
    "acc, stddev = cross_validation_naive_bayes(data, 'BC')\n",
    "test(abs(acc - 0.80) < 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [20 Marks] Task 5 - Tree-augmented Naïve Bayes Classification\n",
    "\n",
    "Similarly to the previous task, implement a Tree-augmented Naïve Bayes (TAN) classifier and evaluate your implementation in the breast cancer dataset. Design a function ``learn_tan_structure(data, class_var)`` to learn the TAN structure (graph) from ``data`` and return such a structure. Scaffolds for required functions are given below. Implement other helper functions as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for learn_tan_structure(data) in one or more cells here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from wikipedia of Conditional mutual information: https://en.wikipedia.org/wiki/Conditional_mutual_information\n",
    "# (Some identities)Alternatively, we may write in terms of joint and conditional entropies as\n",
    "# H(Y|X) = -sigma_x,y p(x,y)*log(p(x,y)/p(x))\n",
    "# then we have I(i;j|C)=H(i|C)+H(j|C)-H(i,j|C)\n",
    "# H(i|C) = -sigma_i,C p(C,i)*log(p(C,i)/p(C))\n",
    "\n",
    "def get_mi(Ai, Aj, class_var, data):\n",
    "    # get p(c)\n",
    "    num_c = dict(data[class_var].value_counts())\n",
    "    p_c = {key: value / len(data) for key, value in num_c.items()}\n",
    "\n",
    "    # get p(Ai,c)\n",
    "    varlist_i = [Ai, class_var]\n",
    "    num_ic = dict(data[varlist_i].value_counts())\n",
    "    p_ic = {key: value / len(data) for key, value in num_ic.items()}\n",
    "    entropyic = 0\n",
    "    # get H(Ai|c) = -sigma_Ai,C p(Ai,C)*log(p(Ai,C)/p(C))\n",
    "    for key, value in p_ic.items():\n",
    "        # key is (outcome of v1, outcome of c)\n",
    "        # so key[-1] is outcome of c, p_c[key[-1]] = p(C)\n",
    "        entropyic -= value * np.log(value / p_c[key[-1]])\n",
    "\n",
    "    # get p(Aj,c)\n",
    "    varlist_j = [Aj, class_var]\n",
    "    num_jc = dict(data[varlist_j].value_counts())\n",
    "    p_jc = {key: value / len(data) for key, value in num_jc.items()}\n",
    "    entropyjc = 0\n",
    "    # get H(Aj|c) = -sigma_Aj,C p(Aj,C)*log(p(Aj,C)/p(C))\n",
    "    for key, value in p_jc.items():\n",
    "        # key is (outcome of v2, outcome of c)\n",
    "        # so key[-1] is outcome of c, p_c[key[-1]] = p(C)\n",
    "        entropyjc -= value * np.log(value / p_c[key[-1]])\n",
    "\n",
    "    # get p(Ai,Aj,c)\n",
    "    varlist_ij = [Ai, Aj, class_var]\n",
    "    num_ijc = dict(data.groupby(varlist_ij).size())\n",
    "    p_ijc = {key: value / len(data) for key, value in num_ijc.items()}\n",
    "    entropyijc = 0\n",
    "    # get H(Ai,Aj|c) = -sigma_Ai,Aj,C p(Ai,Aj,C)*log(p(Ai,Aj,C)/p(C))\n",
    "    for key, value in p_ijc.items():\n",
    "        # key is (outcome of v1, outcome of v2, outcome of c)\n",
    "        # so key[-1] is outcome of c, p_c[key[-1]] = p(C)\n",
    "        entropyijc -= value * np.log(value / p_c[key[-1]])\n",
    "\n",
    "    # I(Ai;Aj|C)=H(Ai|C)+H(Aj|C)-H(Ai,Aj|C)\n",
    "    conditional_mi = entropyic + entropyjc - entropyijc\n",
    "    return conditional_mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph(Graph):\n",
    "    def max_spanning_tree(self, start):\n",
    "        # modify the prim function is Graph.py\n",
    "        # make the weight negative to turn it to a max-heap\n",
    "        \"\"\"\n",
    "                argument\n",
    "                `start`, start vertex\n",
    "                \"\"\"\n",
    "        visited = {start}\n",
    "        Q = []\n",
    "        tree = Graph()\n",
    "        for e in self.adj_list[start]:\n",
    "            pq.heappush(Q, (-self.edge_weights[(start, e)], start, e))\n",
    "        while len(Q) > 0:\n",
    "            weight, v, u = pq.heappop(Q)\n",
    "            weight = -weight\n",
    "            if u not in visited:\n",
    "                visited.add(u)\n",
    "                tree.add_edge(v, u, weight=weight)\n",
    "                for e in self.adj_list[u]:\n",
    "                    if e not in visited:\n",
    "                        pq.heappush(Q, (-self.edge_weights[(u, e)], u, e))\n",
    "        return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_tan_structure(data, class_var='BC'):\n",
    "    '''\n",
    "    Arguments:\n",
    "        data: a dataframe\n",
    "        class_var: The variable you will be classifying with this graph structure\n",
    "    Return:\n",
    "        graph: A Graph object\n",
    "    '''\n",
    "    outcomeSpace = learn_outcome_space(data)\n",
    "    node_list = list(outcomeSpace.keys())\n",
    "\n",
    "    g = Graph({node: [] for node in node_list})\n",
    "    node_list.remove(class_var)\n",
    "\n",
    "    for i in range(len(node_list) - 1):\n",
    "        for j in range(i + 1, len(node_list)):\n",
    "            Ai = node_list[i]\n",
    "            Aj = node_list[j]\n",
    "            conditional_mi = get_mi(Ai, Aj, class_var, data)\n",
    "            g.add_edge(Ai, Aj, conditional_mi, directed=False)\n",
    "    # no gt since the max_spanning_tree algorithm add directions\n",
    "    # undirected edge is represented by two directed edges between two nodes\n",
    "    # when it picks one edge it will discard another to avoid loop\n",
    "    # random start point -- does not affect the outcome of MST\n",
    "    gtd = g.max_spanning_tree(node_list[0])\n",
    "    gtd.add_node(class_var)\n",
    "    gtd.adj_list[class_var] = node_list\n",
    "    return gtd\n",
    "\n",
    "def cross_validation_tan(data, var='BC', k=10):\n",
    "    accuracy_list = []\n",
    "    outcomeSpace = learn_outcome_space(data)\n",
    "    for i in range(k):\n",
    "        # split dataset into train and test\n",
    "\n",
    "        length = int(len(data) / k)\n",
    "        data_train = data.drop([e for e in range(i * length, (i + 1) * length)])\n",
    "        data_test = data.loc[i * length:(i + 1) * length - 1]\n",
    "\n",
    "        # create and train a model\n",
    "\n",
    "        gtd = learn_tan_structure(data_train, var)\n",
    "        model = BayesNet(gtd, outcomeSpace)\n",
    "        model.learn_parameters(data_train)\n",
    "\n",
    "        # test the model with assess_bayes_net\n",
    "        acc = assess_bayes_net(model, data_test)\n",
    "\n",
    "        accuracy_list.append(acc)\n",
    "    return np.mean(accuracy_list), np.std(accuracy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.83295, 0.006262786919575036)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "# tan_graph = learn_tan_structure(data)\n",
    "# test(len(tan_graph.children('BC')) == len(tan_graph)-1)\n",
    "# test('FibrTissueDev' in tan_graph.children('Spiculation') or 'Spiculation' in tan_graph.children('FibrTissueDev'))\n",
    "cross_validation_tan(data,'BC',10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [20 Marks] Task 6 - Report\n",
    "\n",
    "Write a report (**with less than 500 words**) summarising your findings in this assignment. Your report should address the following:\n",
    "\n",
    "a. Make a summary and discussion of the experimental results. You can analyse your results from different aspects such as accuracy, runtime, coding complexity and independence assumptions. You can use plots to illustrate your results.\n",
    "\n",
    "b. Discuss the time and memory complexity of the implemented algorithms.\n",
    "\n",
    "Use Markdown and Latex to write your report in the Jupyter notebook. Develop some plots using Matplotlib to illustrate your results. Be mindful of the maximum number of words. Please, be concise and objective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "This task is to check the d-separation of X, Y and Z. The total runtime is less than 0.4 seconds. It has a time complexity and memory complexity of O(V+E) where V is the total number of vertices and E is the total number of edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "This task consists of 2 parts. For the part of learning outcome space funciton, the time complexity and memory complexity is O(row * column) since the function must iterate through all possible values of each column of the data. The function for probability table learning has a time complexity and memory complexity of O(V * (OutcomeSpaceMax ^ E)), which is mainly contributed by the efforts of constructing the probability table of all the nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1,3)\n",
    "fig.tight_layout()\n",
    "axes[0].title.set_text('Accuracy Values')\n",
    "axes[1].title.set_text('Standard Deviations')\n",
    "axes[2].title.set_text('Runtimes(seconds)')\n",
    "\n",
    "tasks_list = ['Task3', 'Task4', 'Task5']\n",
    "acc_data = pd.Series([0.8412, 0.79185, 0.83295], index=tasks_list)\n",
    "acc_data.plot(kind = 'bar', ax=axes[0])\n",
    "\n",
    "stddev_data = pd.Series([0.00580603134679791, 0.008697844560579362, 0.006262786919575036], index=tasks_list)\n",
    "stddev_data.plot(kind = 'bar', ax=axes[1])\n",
    "\n",
    "time_data = pd.Series([10.6, 9.6, 63.5], index=tasks_list)\n",
    "time_data.plot(kind = 'bar', ax=axes[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks 3-5\n",
    "As for tasks 3 to 5, the overall experimental results can be shown from the figure above. The accuracy of TAN is between the accuracies of Bayesian Network and NBC with the longest runtime.\n",
    "\n",
    "### Task 3\n",
    "The Bayesian Network Classifier has the best overall accuracy and the lowest standard deviation. This is because Bayesian Network Classifier uses the complete graph information and the CPT of all vertices. Because of this property, the time and memory complexity of this task is constructed of 2 parts:\n",
    "1. The maximum size of the CPT table constructed by the markov blanket of the target variable. In the worst case, such size of CPT table is the size of CPT table for all vertices. And this is just the memory complexity of Task 2, which is O(V * (OutcomeSpaceMax ^ E)).\n",
    "2. The size of the testing data, which can be represented by O(row * column), and row and column are the total rows and columns of test data.\n",
    "\n",
    "And total time complexity for the cross validation of Bayesian Network Classifier is O(K(V * (OutcomeSpaceMax ^ E) + row)), where K is the number of the folds. And the memory complexity is O(K(V * (OutcomeSpaceMax ^ E) + row * column)) since the function must use all of the test data.\n",
    "\n",
    "### Task 4\n",
    "The Naive Bayes Classifier has the worst performance with lowest accuracy and highest standard deviation value, since it ignores the relationship between different vertices. The time complexity of this task is O(K(row * OutcomeSpaceMax * V)) which is to construct and search through the probability result for target variable. And the memory complexity is O(K(row * OutcomeSpaceMax * V + row * column)).\n",
    "\n",
    "### Task 5\n",
    "The Tree-augmented Naïve Bayes Classifier (TAN) tends to find the strong connections between vertices but may ignore some of the vertices relationships in most cases. This could explain why it performs slightly worse than the Bayesian Network Classifier. The time complexity is O(K(V^2 * OutcomeSpaceMax^3 + row)) so that it can find the strong inner relationships first then use it to construct the spanning tree, then do the classification. And the space complexity is O(K(V^2 * OutcomeSpaceMax^3 + row * column))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6f8ee94c255eb1f45edb80e83721093c1db1e2ea85447c0854292673b957abb8"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
